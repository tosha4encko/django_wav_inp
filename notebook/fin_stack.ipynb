{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tosha/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/tosha/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics, random_projection, cross_validation, datasets, grid_search, linear_model, metrics, random_projection, manifold, preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import  Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn import manifold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC, OneClassSVM\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import xgboost as xgb\n",
    "from scipy import load, save\n",
    "import sklearn\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1601, 201)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('dataframe/genres_40.csv')\n",
    "dataframe.loc[:, 'm1':] = preprocessing.normalize(dataframe.loc[:, 'm1':])\n",
    "\n",
    "labels = ['hiphop', 'neoclassic', 'jazz', 'rock', 'metal', 'synth', 'pop', 'blues']\n",
    "labels_n = ['neoclassic', 'jazz',  'metal', 'pop']\n",
    "\n",
    "# dataframe = dataframe[dataframe['tag'] == 'neoclassic'].append(dataframe[dataframe['tag'] == 'jazz']).append(dataframe[dataframe['tag'] == 'pop']).append(dataframe[dataframe['tag'] == 'metal'])\n",
    "# dataframe.append(dataframe[dataframe['tag'] == 'pop'])\n",
    "# dataframe = dataframe.append(dataframe[dataframe['tag'] == 'jazz'])\n",
    "# dataframe = dataframe.append(dataframe[dataframe['tag'] == 'metal'])\n",
    "dataframe = dataframe.sample(frac=1)\n",
    "\n",
    "shape(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 0]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_cl(arr):\n",
    "    list_max_i = []\n",
    "    for a in arr:\n",
    "        max_el = 0\n",
    "        max_i = 0\n",
    "        for i in range(len(a)):\n",
    "            if a[i] > max_el:\n",
    "                max_el = a[i]\n",
    "                max_i = i\n",
    "        list_max_i += [max_i]\n",
    "    return list_max_i\n",
    "\n",
    "max_cl([[1,2,3], [2,6,4], [8,1,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1350, 201)\n"
     ]
    }
   ],
   "source": [
    "def search_abnom(dataframe, label, g, nu):\n",
    "    svm_ = OneClassSVM(gamma=g, nu=nu)\n",
    "    svm_.fit(dataframe[dataframe['tag'] == label].loc[:, 'm1':])\n",
    "    l = svm_.predict(dataframe[dataframe['tag'] == label].loc[:, 'm1':])\n",
    "    return l\n",
    "\n",
    "labels = ['hiphop', 'classical', 'jazz', 'rock', 'metal', 'synth', 'pop', 'blues']\n",
    "for label in labels:\n",
    "    svm_label = search_abnom(dataframe, label, 2, 0.15).tolist()\n",
    "    dataframe[dataframe['tag'] == label] = dataframe[dataframe['tag'] == label][np.array(svm_label) == 1]\n",
    "    dataframe = dataframe.dropna()\n",
    "print(shape(dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'hiphop':0, 'classical':1, 'jazz':2, 'rock':3, 'metal':4, 'synth':5, 'pop':6, 'blues': 7} \n",
    "int_label = []\n",
    "for label in dataframe['tag']:\n",
    "    int_label.append(label_dict[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1350,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# svm_label = []\n",
    "# for label in labels:\n",
    "#     svm_label += search_abnom(label, 2, 0.01).tolist()\n",
    "# dataframe_svm = dataframe[np.array(svm_label) == 1]\n",
    "\n",
    "# dataframe_svm_t = np.array(dataframe_svm.loc[:, 'm1':])\n",
    "# dataframe_svm_l = np.array(dataframe_svm['tag'])\n",
    "\n",
    "dataframe_svm_t = np.array(dataframe.loc[:, 'm1':])\n",
    "dataframe_svm_l = np.array(int_label)\n",
    "dataframe_t = dataframe.loc[:, 'm1':]\n",
    "np.shape(dataframe_svm_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcc = SVC(C=10, gamma=5, kernel = 'rbf', probability=True)\n",
    "lrc = LogisticRegression(C = 430)\n",
    "knc = KNeighborsClassifier(weights = 'distance', n_neighbors=7, metric = 'manhattan')\n",
    "rfc = RandomForestClassifier(max_depth=23, n_estimators=1300, random_state=1)\n",
    "xgbc = xgb.XGBClassifier(silent=False, nthread=4, max_depth=2, n_estimators=4000, learning_rate=0.009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fin_classif(list_model, list_param, list_name):\n",
    "    list_preds_f = []\n",
    "    list_labels_f = []\n",
    "    for train_ind, test_ind in cross_validation.StratifiedKFold(dataframe_svm_l, n_folds=5, shuffle=True, \n",
    "                                                                random_state=1):\n",
    "        np.random.shuffle(train_ind) \n",
    "        np.random.shuffle(test_ind)\n",
    "\n",
    "#         f_df = dataframe_svm_t[:, :]\n",
    "#         s_df = dataframe_svm_t[:, :]\n",
    "\n",
    "#         df_ = dataframe_svm_t[:, list_param[0]]\n",
    "#         svcc.fit(df_[train_ind], dataframe_svm_l[train_ind])\n",
    "#         list_preds = list_model[0].predict_proba(df_[test_ind])\n",
    "        list_preds = np.array()\n",
    "        for i in range(len(list_model)):\n",
    "            df_ = dataframe_svm_t[:, list_param[i]]\n",
    "            list_model[i].fit(df_[train_ind], dataframe_svm_l[train_ind])\n",
    "            list_preds = np.hstack((list_preds, list_model[i].predict_proba(df_[test_ind]))\n",
    "            scipy.save(list_name[i], list_model[i].predict_proba(df_[test_ind]))\n",
    "        \n",
    "#         print(shape(list_labels_f))\n",
    "#         if list_preds_f == []:\n",
    "#             list_preds_f = list_preds\n",
    "#             list_labels_f = dataframe_svm_l[test_ind]\n",
    "#         else:\n",
    "#             list_preds_f  = np.vstack((list_preds_f, list_preds))\n",
    "          list_labels_f = np.hstack((list_labels_f, dataframe_svm_l[test_ind]))\n",
    "#     return list_preds_f, list_labels_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin_classif([lrc, knc, svcc, rfc, xgbc], [load('regr_param.npy'), load('regr_param.npy'), load('regr_param.npy'), \n",
    "                               load('boost_param.npy'), load('boost_param.npy')],\n",
    "                              ['lrc.npy', 'knc.npy', 'svcc.npy', 'rfc.npy', 'xgbc.npy',])\n",
    "# print(shape(rl), shape(ll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc_ridge_scoring1 = cross_validation.cross_val_score(rfc, rl1, ll1,\n",
    "                                                  scoring='f1_weighted', cv = 5)\n",
    "print('lrc --  mean:{}, max:{}, min:{}, std:{}'.format(lrc_ridge_scoring1.mean(), lrc_ridge_scoring1.max(),\n",
    "                                                     lrc_ridge_scoring1.min(), lrc_ridge_scoring1.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import save\n",
    "save('rl.npy', rl)\n",
    "save('ll.npy', ll)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
