{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics, random_projection, cross_validation, datasets, grid_search, linear_model, metrics, random_projection, manifold, preprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import  Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import RandomizedPCA\n",
    "from sklearn import manifold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.svm import SVC, OneClassSVM\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import xgboost as xgb\n",
    "from scipy import load, save\n",
    "import sklearn\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1601, 201)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.read_csv('dataframe/genres_40.csv')\n",
    "dataframe.loc[:, 'm1':] = preprocessing.normalize(dataframe.loc[:, 'm1':])\n",
    "\n",
    "labels = ['hiphop', 'neoclassic', 'jazz', 'rock', 'metal', 'synth', 'pop', 'blues']\n",
    "labels_n = ['neoclassic', 'jazz',  'metal', 'pop']\n",
    "\n",
    "# dataframe = dataframe[dataframe['tag'] == 'neoclassic'].append(dataframe[dataframe['tag'] == 'jazz']).append(dataframe[dataframe['tag'] == 'pop']).append(dataframe[dataframe['tag'] == 'metal'])\n",
    "# dataframe.append(dataframe[dataframe['tag'] == 'pop'])\n",
    "# dataframe = dataframe.append(dataframe[dataframe['tag'] == 'jazz'])\n",
    "# dataframe = dataframe.append(dataframe[dataframe['tag'] == 'metal'])\n",
    "dataframe = dataframe.sample(frac=1)\n",
    "\n",
    "shape(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1351, 201)\n"
     ]
    }
   ],
   "source": [
    "def search_abnom(dataframe, label, g, nu):\n",
    "    svm_ = OneClassSVM(gamma=g, nu=nu)\n",
    "    svm_.fit(dataframe[dataframe['tag'] == label].loc[:, 'm1':])\n",
    "    l = svm_.predict(dataframe[dataframe['tag'] == label].loc[:, 'm1':])\n",
    "    return l\n",
    "\n",
    "labels = ['hiphop', 'classical', 'jazz', 'rock', 'metal', 'synth', 'pop', 'blues']\n",
    "for label in labels:\n",
    "    svm_label = search_abnom(dataframe, label, 2, 0.15).tolist()\n",
    "    dataframe[dataframe['tag'] == label] = dataframe[dataframe['tag'] == label][np.array(svm_label) == 1]\n",
    "    dataframe = dataframe.dropna()\n",
    "print(shape(dataframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {'hiphop':0, 'classical':1, 'jazz':2, 'rock':3, 'metal':4, 'synth':5, 'pop':6, 'blues': 7} \n",
    "int_label = []\n",
    "for label in dataframe['tag']:\n",
    "    int_label.append(label_dict[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1351,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# svm_label = []\n",
    "# for label in labels:\n",
    "#     svm_label += search_abnom(label, 2, 0.01).tolist()\n",
    "# dataframe_svm = dataframe[np.array(svm_label) == 1]\n",
    "\n",
    "# dataframe_svm_t = np.array(dataframe_svm.loc[:, 'm1':])\n",
    "# dataframe_svm_l = np.array(dataframe_svm['tag'])\n",
    "\n",
    "dataframe_svm_t = np.array(dataframe.loc[:, 'm1':])\n",
    "dataframe_svm_l = np.array(int_label)\n",
    "dataframe_t = dataframe.loc[:, 'm1':]\n",
    "np.shape(dataframe_svm_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcc = SVC(C=10, gamma=5, kernel = 'rbf', probability=True)\n",
    "lrc = LogisticRegression(C = 430)\n",
    "knc = KNeighborsClassifier(weights = 'distance', n_neighbors=7, metric = 'manhattan')\n",
    "rfc = RandomForestClassifier(max_depth=23, n_estimators=1300, random_state=1)\n",
    "xgbc = xgb.XGBClassifier(silent=False, nthread=4, max_depth=2, n_estimators=4000, learning_rate=0.009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_cl(arr):\n",
    "    list_max_i = []\n",
    "    for a in arr:\n",
    "        max_el = 0\n",
    "        max_i = 0\n",
    "        for i in range(len(a)):\n",
    "            if a[i] > max_el:\n",
    "                max_el = a[i]\n",
    "                max_i = i\n",
    "        list_max_i += [max_i]\n",
    "    return list_max_i\n",
    "\n",
    "\n",
    "def cross_preds(list_model, list_param, list_save_name):\n",
    "    list_preds_f = np.array([])\n",
    "    list_labels_f = np.array([])\n",
    "\n",
    "    for train_ind, test_ind in cross_validation.StratifiedKFold(dataframe_svm_l, n_folds=5, shuffle=True):\n",
    "        np.random.shuffle(train_ind) \n",
    "        np.random.shuffle(test_ind)\n",
    "        \n",
    "        df_ = dataframe_svm_t[:, list_param[0]] \n",
    "        list_model[0].fit(df_[train_ind], dataframe_svm_l[train_ind])\n",
    "        list_preds = list_model[0].predict_proba(df_[test_ind])\n",
    "        \n",
    "        for i in range(1, len(list_model)):\n",
    "            df_ = dataframe_svm_t[:, list_param[i]] \n",
    "            list_model[i].fit(df_[train_ind], dataframe_svm_l[train_ind])\n",
    "            list_preds = np.hstack((list_preds, list_model[i].predict_proba(df_[test_ind])))\n",
    "            \n",
    "        if len(list_preds_f) == 0:\n",
    "            list_preds_f = list_preds\n",
    "            list_labels_f = dataframe_svm_l[test_ind]\n",
    "        else:\n",
    "            list_preds_f = np.vstack((list_preds_f, list_preds))\n",
    "            list_labels_f = np.hstack((list_labels_f, dataframe_svm_l[test_ind]))\n",
    "\n",
    "    for i in range(len(list_save_name)):\n",
    "        save(list_save_name[i], list_preds_f[:, i*8:(i+1)*8])\n",
    "    save('labels.npy', list_labels_f)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8915929203539823"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(load('labels.npy'), \n",
    "                       max_cl(3*load('svcc.npy') + 3*load('rfc.npy') + 2*load('lrc.npy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimizefc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_func(x1, x2, x3):\n",
    "    return -metrics.accuracy_score(load('labels.npy'), \n",
    "                                   max_cl(x1*load('rfc.npy') + x2*load('svcc.npy') + x3*load('lrc.npy')))\n",
    "\n",
    "def res_cl_report(x1, m1, x2,  m2, x3,  m3):\n",
    "    print(metrics.classification_report(load('labels.npy'), \n",
    "                                   max_cl(x1*m1 + x2*m2)))\n",
    "    \n",
    "def s_func(x):\n",
    "    return res_func(*x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tosha/anaconda3/lib/python3.6/site-packages/scipy/optimize/_minimize.py:430: RuntimeWarning: Method Nelder-Mead cannot handle constraints nor bounds.\n",
      "  RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " final_simplex: (array([[0.00038735, 0.00041512, 0.0001466 ],\n",
       "       [0.00039121, 0.00041872, 0.00014826],\n",
       "       [0.0003934 , 0.00041616, 0.00014925],\n",
       "       [0.00039074, 0.00041685, 0.00014472]]), array([-0.89454277, -0.89454277, -0.89454277, -0.89454277]))\n",
       "           fun: -0.894542772861357\n",
       "       message: 'Optimization terminated successfully.'\n",
       "          nfev: 47\n",
       "           nit: 19\n",
       "        status: 0\n",
       "       success: True\n",
       "             x: array([0.00038735, 0.00041512, 0.0001466 ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = (0,0,0)\n",
    "bnds = ((0, 1), (0, 1), (0, 1))\n",
    "res = minimize(s_func, x0, method='Nelder-Mead', bounds = bnds)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = load('knc.npy') + load('rfc.npy') + load('svcc.npy')\n",
    "d2 = load('svcc.npy') + load('lrc.npy') + load('rfc.npy')\n",
    "d3 = load('svcc.npy') + load('knc.npy') + load('rfc.npy')\n",
    "d4 = load('svcc.npy') + load('knc.npy') + load('lrc.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.82      0.81       168\n",
      "          1       0.94      0.95      0.94       167\n",
      "          2       0.90      0.85      0.88       169\n",
      "          3       0.70      0.68      0.69       171\n",
      "          4       0.88      0.87      0.87       171\n",
      "          5       0.91      0.89      0.90       169\n",
      "          6       0.79      0.81      0.80       172\n",
      "          7       0.75      0.76      0.76       169\n",
      "\n",
      "avg / total       0.83      0.83      0.83      1356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_cl_report(1, load('rfc.npy'), 1, load('rfc.npy'), 1, load('svcc.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save('best_coef2', [1.30831118e-04, 9.98999037e-06, 4.07361090e-04, 3.26582233e-05,\n",
    "       8.15057852e-05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.hstack((d1, d2, d3, d4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "svcc = SVC(C=1, gamma=1, kernel = 'rbf', probability=True)\n",
    "lrc = LogisticRegression(C = 430)\n",
    "knc = KNeighborsClassifier(weights = 'distance', n_neighbors=27, metric = 'manhattan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=23, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1300, n_jobs=1,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(data, load('labels.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1356, 16)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[:, rfc.feature_importances_ > np.median(rfc.feature_importances_)*1]\n",
    "shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lrc --  mean:0.8486418465857042, max:0.8758065749865688, min:0.80669180558144, std:0.02666024137961361\n"
     ]
    }
   ],
   "source": [
    "lrc_ridge_scoring1 = cross_validation.cross_val_score(rfc, data, load('labels.npy'),\n",
    "                                                  scoring='f1_weighted', cv = 5)\n",
    "print('lrc --  mean:{}, max:{}, min:{}, std:{}'.format(lrc_ridge_scoring1.mean(), lrc_ridge_scoring1.max(),\n",
    "                                                     lrc_ridge_scoring1.min(), lrc_ridge_scoring1.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
